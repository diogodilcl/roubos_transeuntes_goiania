{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "12b0e1de8bdb4ff0ea90f512f530735d56972c83",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.layers import Dropout\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "f4aaa7a2a018c5e900b42abe242e44a14adf5c09",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "cca4e13dc953075a0e79cdd7d06d19bf47110a07",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diogodil/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/diogodil/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/diogodil/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/diogodil/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/diogodil/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/diogodil/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\\\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "dataframe = pandas.read_csv('roubos.csv', index_col=0, parse_dates=True)\n",
    "dataset = dataframe['2011-01-01':]\n",
    "# dataset = dataset.values\n",
    "dataset['qtd'] = dataset['qtd'].astype('float32')\n",
    "dataset.drop('tipo', axis=1, inplace=True)\n",
    "dataset.drop('mes', axis=1, inplace=True)\n",
    "dataset.drop('ano', axis=1, inplace=True)\n",
    "dataset.loc[dataset['bairro'] =='CENTRAL','bairro'] = 1.0\n",
    "dataset.loc[dataset['bairro'] =='NOROESTE','bairro'] = 2.0\n",
    "dataset.loc[dataset['bairro'] =='SUDOESTE','bairro'] = 3.0\n",
    "dataset.loc[dataset['bairro'] =='OESTE','bairro'] = 4.0\n",
    "dataset.loc[dataset['bairro'] =='SUL','bairro'] = 5.0\n",
    "dataset.loc[dataset['bairro'] =='LESTE','bairro'] = 6.0\n",
    "dataset.loc[dataset['bairro'] =='NORTE','bairro'] = 7.0\n",
    "dataset['qtd'] = dataset['qtd'].astype('float32')\n",
    "dataset = dataset.loc[dataset['bairro'] == 7]\n",
    "dataset.drop('bairro', axis=1, inplace=True)\n",
    "result = seasonal_decompose(dataset, model='additive')\n",
    "dataset = result.trend.dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "679555290bec65b86f56beec4d5f57b6b902c2d8",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.58333333],\n",
       "       [69.25      ],\n",
       "       [72.125     ],\n",
       "       [73.5       ],\n",
       "       [74.29166667]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "4b770f9e058d3a35ef954aab175b59066fa35e7f",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "fd5b7974b9a2f3969d6ed1e9e6800aded9d457cb",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.02750322],\n",
       "       [0.05715514],\n",
       "       [0.07133648],\n",
       "       [0.0795015 ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 12\n",
      "[[0.         0.        ]\n",
      " [0.         0.02750322]\n",
      " [0.02750322 0.05715514]\n",
      " [0.05715514 0.07133648]\n",
      " [0.07133648 0.0795015 ]\n",
      " [0.0795015  0.09325312]\n",
      " [0.09325312 0.10915342]\n",
      " [0.10915342 0.10958315]\n",
      " [0.10958315 0.09926945]\n",
      " [0.09926945 0.08680705]\n",
      " [0.08680705 0.08036098]\n",
      " [0.08036098 0.0850881 ]\n",
      " [0.0850881  0.09712076]\n",
      " [0.09712076 0.09454233]\n",
      " [0.09454233 0.08981521]\n",
      " [0.08981521 0.09368285]\n",
      " [0.09368285 0.10657499]\n",
      " [0.10657499 0.12290503]\n",
      " [0.12290503 0.13923507]\n",
      " [0.13923507 0.1611517 ]\n",
      " [0.1611517  0.17576278]\n",
      " [0.17576278 0.17748174]\n",
      " [0.17748174 0.1736141 ]\n",
      " [0.1736141  0.17189514]\n",
      " [0.17189514 0.17963043]\n",
      " [0.17963043 0.20283627]\n",
      " [0.20283627 0.23162871]\n",
      " [0.23162871 0.26171036]\n",
      " [0.26171036 0.28620541]\n",
      " [0.28620541 0.2939407 ]\n",
      " [0.2939407  0.29565965]\n",
      " [0.29565965 0.31155995]\n",
      " [0.31155995 0.33691448]\n",
      " [0.33691448 0.36914482]\n",
      " [0.36914482 0.40567254]\n",
      " [0.40567254 0.44305973]\n",
      " [0.44305973 0.47614955]\n",
      " [0.47614955 0.50666094]\n",
      " [0.50666094 0.52986678]\n",
      " [0.52986678 0.55135367]\n",
      " [0.55135367 0.57842716]\n",
      " [0.57842716 0.61495488]\n",
      " [0.61495488 0.66652342]\n",
      " [0.66652342 0.71078642]\n",
      " [0.71078642 0.75075204]\n",
      " [0.75075204 0.80403954]\n",
      " [0.80403954 0.85818651]\n",
      " [0.85818651 0.90631715]\n",
      " [0.90631715 0.95530726]\n",
      " [0.95530726 0.98238075]\n",
      " [0.98238075 0.99398367]\n",
      " [0.99398367 1.        ]\n",
      " [1.         0.98624839]\n",
      " [0.98624839 0.98109153]\n",
      " [0.98109153 0.97808337]\n",
      " [0.97808337 0.96862914]\n",
      " [0.96862914 0.95530726]\n",
      " [0.95530726 0.92952299]\n",
      " [0.92952299 0.8990116 ]\n",
      " [0.8990116  0.8478728 ]\n",
      " [0.8478728  0.79974216]\n",
      " [0.79974216 0.78126343]\n",
      " [0.78126343 0.7718092 ]\n",
      " [0.7718092  0.74731414]\n",
      " [0.74731414 0.72410829]\n",
      " [0.72410829 0.69273743]\n",
      " [0.69273743 0.66523421]\n",
      " [0.66523421 0.64933391]\n",
      " [0.64933391 0.62526859]\n",
      " [0.62526859 0.59432746]\n",
      " [0.59432746 0.56252686]\n",
      " [0.56252686 0.5345939 ]]\n"
     ]
    }
   ],
   "source": [
    "look_back = 1\n",
    "supervised = timeseries_to_supervised(dataset, look_back)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "train_size = int(len(supervised_values) * 0.84)\n",
    "train, test = supervised_values[0:train_size], supervised_values[train_size:len(supervised_values)]\n",
    "print(len(train), len(test))\n",
    "print(supervised_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_uuid": "518f503c0ee584f9769df61971984e2c233ab09a",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX, trainY = train[:, 0:-1], train[:, -1]\n",
    "testX, testY = test[:, 0:-1], test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY = numpy.array(trainX), numpy.array(trainY)\n",
    "testX, testY = numpy.array(testX), numpy.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa88e5e7cafa406a83b6b96f1df9165dec229716",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "290989326be83ea0307367ebb60f0e54b27a24dd",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "# model.add(LSTM(16, input_shape=(1, look_back), return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# # model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(8))\n",
    "model.add(LSTM(14, input_shape=(1, look_back), return_sequences=True))\n",
    "model.add(LSTM(14, return_sequences=True))\n",
    "model.add(LSTM(14, return_sequences=True))\n",
    "model.add(LSTM(8))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# for i in range(30):\n",
    "#     model.fit(trainX, trainY, epochs=1, batch_size=1, verbose=0)\n",
    "#     model.reset_states()\n",
    "model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d42eb6f7083b8dbddeef367f9edbffca379f2d7",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "# trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "last = trainY\n",
    "last2 = testX\n",
    "# trainPredict2 = scaler.inverse_transform(trainPredict)\n",
    "trainY2 = scaler.inverse_transform([trainY])\n",
    "testPredict2 = scaler.inverse_transform(testPredict)\n",
    "testY2 = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "# trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "# print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY2[0], testPredict2[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "print(r2_score(testY2[0],testPredict2[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "060b0eedbc021e7b094b8f5e10e4941ec703633f",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(testY2[0])\n",
    "plt.plot(testPredict2[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(r2_score(testY2[0],testPredict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(math.sqrt(mean_squared_error(testY2[0], testPredict2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create and fit the LSTM network\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(16, input_shape=(1, look_back), return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(8))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.add(LSTM(16, input_shape=(1, look_back), return_sequences=True))\n",
    "# model.add(LSTM(12, return_sequences=True))\n",
    "# model.add(LSTM(12, return_sequences=True))\n",
    "# model.add(LSTM(12, return_sequences=True))\n",
    "# model.add(LSTM(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.add(LSTM(16, input_shape=(1, look_back), return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(16, return_sequences=True))\n",
    "# model.add(LSTM(8))\n",
    "# model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.add(LSTM(20, input_shape=(1, look_back), return_sequences=True))\n",
    "# model.add(LSTM(20, return_sequences=True))\n",
    "# model.add(LSTM(20, return_sequences=True))\n",
    "# model.add(LSTM(20, return_sequences=True))\n",
    "# model.add(LSTM(20, return_sequences=True))\n",
    "# model.add(LSTM(20, return_sequences=True))\n",
    "# model.add(LSTM(20, return_sequences=True))\n",
    "# model.add(LSTM(20, return_sequences=True))\n",
    "# model.add(LSTM(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.add(LSTM(14, input_shape=(1, look_back), return_sequences=True))\n",
    "# model.add(LSTM(14, return_sequences=True))\n",
    "# model.add(LSTM(14, return_sequences=True))\n",
    "# model.add(LSTM(14, return_sequences=True))\n",
    "# model.add(LSTM(14, return_sequences=True))\n",
    "# model.add(LSTM(14, return_sequences=True))\n",
    "# model.add(LSTM(14, return_sequences=True))\n",
    "# model.add(LSTM(14, return_sequences=True))\n",
    "# model.add(LSTM(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(testX[-1:])\n",
    "# # print(last2)\n",
    "# model.predict(testX[-1:])\n",
    "\n",
    "testX[-1][0][1] = testX[-1][0][0]\n",
    "testX[-1][0][0] = 0.30748665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = list()\n",
    "for i in range(6):\n",
    "    predict = model.predict(testX[-1:])\n",
    "    testX[-1][0][1] = testX[-1][0][0]\n",
    "    testX[-1][0][0] = predict\n",
    "    predictions.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(predictions)\n",
    "predictions2 = [x[0] for x in predictions]\n",
    "scaler.inverse_transform(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testX[-1][0][1] = testX[-1][0][0]\n",
    "testX[-1][0][0] = 0.30748665\n",
    "model.predict(testX[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testX[-1][0][1] = testX[-1][0][0]\n",
    "testX[-1][0][0] = 0.40585274\n",
    "model.predict(testX[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler.inverse_transform(0.43825415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler.inverse_transform(0.40585274)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler.inverse_transform(0.39879677)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neurons = 512                 \n",
    "activation_function = 'tanh'  \n",
    "loss = 'mse'                  \n",
    "optimizer=\"adam\"              \n",
    "dropout = 0.25                 \n",
    "batch_size = 12               \n",
    "epochs = 53                   \n",
    "window_len = 7               \n",
    "training_size = 0.8\n",
    "merge_date = '2016-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# def build_model(inputs, output_size, neurons, activ_func=activation_function, dropout=dropout, loss=loss, optimizer=optimizer):\n",
    "#     \"\"\"\n",
    "#     inputs: input data as numpy array\n",
    "#     output_size: number of predictions per input sample\n",
    "#     neurons: number of neurons/ units in the LSTM layer\n",
    "#     active_func: Activation function to be used in LSTM layers and Dense layer\n",
    "#     dropout: dropout ration, default is 0.25\n",
    "#     loss: loss function for calculating the gradient\n",
    "#     optimizer: type of optimizer to backpropagate the gradient\n",
    "#     This function will build 3 layered RNN model with LSTM cells with dripouts after each LSTM layer \n",
    "#     and finally a dense layer to produce the output using keras' sequential model.\n",
    "#     Return: Keras sequential model and model summary\n",
    "#     \"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, return_sequences=True, input_shape=(inputs.shape[1], inputs.shape[2]), activation=activ_func))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(LSTM(neurons, return_sequences=True, activation=activ_func))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(LSTM(neurons, activation=activ_func))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(Dense(units=output_size))\n",
    "#     model.add(Activation(activ_func))\n",
    "#     model.compile(loss=loss, optimizer=optimizer, metrics=['mae'])\n",
    "#     model.summary()\n",
    "#     return model\n",
    "# btc_model = build_model(X_train, output_size=1, neurons=neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
